{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thien2001git/HoangXuanThienDoAnTotNghiep/blob/main/AudioFilter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FdfTBDdJETY1",
        "outputId": "56ffb4f6-67c5-469a-ed14-00a52786edc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-io in /usr/local/lib/python3.10/dist-packages (0.32.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.32.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-io) (0.32.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "P6b7FQgyEgLz"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import tensorflow_io as tfio\n",
        "from keras import layers\n",
        "from keras import models\n",
        "import os\n",
        "import librosa\n",
        "import pickle\n",
        "from IPython.display import Audio\n",
        "from IPython.core.display import display\n",
        "import random\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Conv1D, MaxPooling1D, Dropout\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "G9803TCcEzu2"
      },
      "outputs": [],
      "source": [
        "def getAllFile(root):\n",
        "    l = []\n",
        "    for path, subdirs, files in os.walk(root):\n",
        "        for name in files:\n",
        "            l.append(os.path.join(path, name))\n",
        "    return l\n",
        "def dumpToFile(obj, path):\n",
        "    with open(path, 'wb') as file:\n",
        "        pickle.dump(obj, file)\n",
        "def loadToObj(path):\n",
        "    with open(path, 'rb') as file:\n",
        "        return pickle.load(file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "peOqQLfmEwqG"
      },
      "outputs": [],
      "source": [
        "path = [\"drive/MyDrive/distant_16k.bin\",\n",
        "        \"drive/MyDrive/source_16k_train.bin\",\n",
        "        'drive/MyDrive/speech_train.bin',\n",
        "        \"drive/MyDrive/source_16k_test.bin\",\n",
        "        \"drive/MyDrive/speech_test.bin\", ]\n",
        "# distant_16k = loadToObj(path[0])\n",
        "source_16k_train = loadToObj(path[1])\n",
        "speech_train = loadToObj(path[2])\n",
        "source_16k_test = loadToObj(path[3])\n",
        "speech_test = loadToObj(path[4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "DzU9k4SpGAdb"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(\"/content/drive/MyDrive/VOiCES_devkit/references/train_index.csv\")\n",
        "test = pd.read_csv(\"/content/drive/MyDrive/VOiCES_devkit/references/test_index.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3hIJecKiI35t"
      },
      "outputs": [],
      "source": [
        "SR = 16000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "fw72Br_XGJp-"
      },
      "outputs": [],
      "source": [
        "def toSound(e):\n",
        "    file = os.path.join(\"/content/drive/MyDrive/VOiCES_devkit\", e)\n",
        "    \n",
        "    y, sr = librosa.load(file, sr = 16000)\n",
        "    y = y[:16000*18]\n",
        "    zr = np.zeros((16000*18 - y.shape[0]))\n",
        "    y = np.append(y, zr)\n",
        "    audio_slices = tf.keras.utils.timeseries_dataset_from_array(y,y,sequence_length=48000,sequence_stride=48000,batch_size=1)\n",
        "    l = []\n",
        "\n",
        "    for i in audio_slices:\n",
        "        e1 = i[0].numpy()[0]\n",
        "        l.append(e1)\n",
        "        # spectrogram = librosa.feature.melspectrogram(y=e1, sr=sr)\n",
        "        # spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n",
        "        # spectrogram = (spectrogram - spectrogram.min()) / (spectrogram.max() - spectrogram.min())\n",
        "        # l.append(spectrogram)\n",
        "    return l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "F17YT1rRH3-7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "eD9WeO15UH8e"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "TPB0o6o9JWZh"
      },
      "outputs": [],
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "\n",
        "for i in train['filename'][:200]:\n",
        "    X_train.extend(toSound(i))\n",
        "for i in train['source'][:200]:\n",
        "    y_train.extend(toSound(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "7vcltbhML0-D"
      },
      "outputs": [],
      "source": [
        "X_test = []\n",
        "y_test = []\n",
        "\n",
        "for i in test['filename'][:20]:\n",
        "    X_test.extend(toSound(i))\n",
        "for i in test['source'][:20]:\n",
        "    y_test.extend(toSound(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "925iCuSINj_a",
        "outputId": "99d243fa-3ede-4fa4-ffc9-8607f7049a9c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "len(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hop_length = int(math.pow(2,10))\n",
        "def showSome(y, sr):\n",
        "    \n",
        "    # librosa.display.waveshow(y)\n",
        "    # plt.show()\n",
        "    \n",
        "    img = librosa.display.specshow(y, y_axis='log', sr=sr, hop_length=hop_length,\n",
        "                            x_axis='time')"
      ],
      "metadata": {
        "id": "eh3cGrGMM1fV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6p_3wKSPgQ7",
        "outputId": "83585bc5-fdb4-4c40-c441-b72e1b924ef2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48000,)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bCclZ2BwFlpy",
        "outputId": "e2eab404-66d4-4827-9483-9b3c3f229b97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"audio_filter_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_audio (InputLayer)    [(None, 48000, 1)]        0         \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 48000, 64)         256       \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 48000, 128)        24704     \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 48000, 256)        98560     \n",
            "                                                                 \n",
            " conv1d_3 (Conv1D)           (None, 48000, 1)          769       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 124,289\n",
            "Trainable params: 124,289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "input_shape=(48000, 1)\n",
        "from keras.layers import Input, Conv1D, Conv1DTranspose\n",
        "from keras.models import Model\n",
        "\n",
        "def create_audio_filter_model(input_shape):\n",
        "    # Định nghĩa đầu vào\n",
        "    input_audio = Input(shape=input_shape, name='input_audio')\n",
        "\n",
        "    # Phần encoder\n",
        "    x = Conv1D(64, 3, activation='relu', padding='same')(input_audio)\n",
        "    x = Conv1D(128, 3, activation='relu', padding='same')(x)\n",
        "    x = Conv1D(256, 3, activation='relu', padding='same')(x)\n",
        "\n",
        "    # Phần decoder\n",
        "    # x = Conv1DTranspose(256, 3, strides=1, activation='relu', padding='same')(encoded)\n",
        "    # x = Conv1DTranspose(64, 3, strides=1, activation='relu', padding='same')(x)\n",
        "    decoded = Conv1D(1, 3, activation='linear', padding='same')(x)\n",
        "\n",
        "    # Định nghĩa mô hình\n",
        "    model = Model(inputs=input_audio, outputs=decoded, name='audio_filter_model')\n",
        "\n",
        "    # Compile mô hình\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "model = create_audio_filter_model(input_shape)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zrw2ZnIJF6LW",
        "outputId": "dbe4bed9-647b-4b04-afb2-6714f1a78445"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "16/24 [===================>..........] - ETA: 6:24 - loss: 0.0111"
          ]
        }
      ],
      "source": [
        "history = model.fit(np.array(X_train),np.array(y_train),batch_size=50,epochs=10,validation_data=(np.array(X_test),np.array(y_test)), callbacks=tf.keras.callbacks.EarlyStopping(verbose=1, \n",
        "                                               patience=5,\n",
        "                                               restore_best_weights=True\n",
        "                                              ), )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ti4ESR_fKydw"
      },
      "outputs": [],
      "source": [
        "metrics = history.history\n",
        "plt.plot(history.epoch, metrics['val_mean_absolute_error'])\n",
        "plt.legend(['val_mean_absolute_error'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ccAF67HIPamh"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.epoch, metrics['val_loss'])\n",
        "plt.legend(['val_loss'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHrk0E9_RPFl"
      },
      "outputs": [],
      "source": [
        "v = model.predict(np.array(X_test[:1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JHJS8I2DWEon"
      },
      "outputs": [],
      "source": [
        "v"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vrUZsPmFnSkm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1o11fl1aSz6WqDr8KFGHht48FKTpq1sv1",
      "authorship_tag": "ABX9TyPezUQicVKBA41TaVyTo+lN",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}